---
title: "Integrating AI Assistants into Shiny Apps"
subtitle: "Simplify Development and Enhance User Experience"
author: "James Wade"
abstract: "Incorporating AI assistants powered by large language models into your Shiny applications can streamline development and significantly improve user experience. This presentation will highlight practical patterns for integrating these assistants, making app building easier and more efficient. We will also explore emerging tools that expand the possibilities of AI integration, enabling you to create more interactive and intelligent Shiny apps."
footer: "jameshwade.github.io/r-pharma-talk"
format:
  revealjs:
    logo: images/dow.svg
    preview-links: auto
    margin: 0.05
    fig-align: center
    theme: [default, custom.scss]
---

## AI Coding Assistants {.center}

<br>

::: columns
::: {.column width="33%"}
![[`chattr`](https://github.com/mlverse/chattr)](images/chattr.png){height="250px"}
:::

::: {.column width="33%"}
![[`gptstudio`](https://github.com/michelnivard/gptstudio)](images/gptstudio.png){width="250px"}
:::

::: {.column width="33%"}
![[Github Copilot](https://github.com/features/copilot)](images/github-copilot.png){height="250px"}
:::
:::

## Sidebots

![Joe Cheng's talk "Shiny x AI" at posit::conf(2024)](images/sidebot.png){.rounded-shadow}

## [You just saw some awesome AI examples from Joe]{.r-fit-text} {.center}

![Joe's talk a few hours ago](images/paste-3.png){.rounded-shadow fig-align="center" width="450" height="256"}

## New Tools for LLMs from Posit {.smaller}

::: {nonincremental}
-   [`elmer`](https://github.com/hadley/elmer)
    -   [x] Basic API calls across many service
    -   [ ] Multimodal chats: text + images
    -   [x] Tool calling
    -   [ ] Structured output
-   [`shinychat`](https://github.com/jcheng5/shinychat)
    -   [x] Simple app demo
    -   [x] Fancier app demo (sidebots!)
:::

## Let's take a few minutes to dive in {.center}

## Advice from Joe {auto-animate="true"}

::: columns
::: {.column width="50%"}
> Being a mere consumer of Copilot and ChatGPT is not enough to have a well-informed opinion of the potential of LLMs (you will miss out on structured output and tool calls).
>
> **Start coding!**
:::

::: {.column width="50%"}
![](images/robot-assistant.jpeg){.rounded-shadow}
:::
:::

## Advice from Joe {auto-animate="true"}

<br>

::: columns
::: {.column width="40%"}
![Stochastic Parrot](images/stochastic_parrot.jpeg){.rounded-shadow}
:::
:::

## Advice from Joe {auto-animate="true"}

<br>

::: columns
::: {.column width="40%"}
![Stochastic Parrot](images/stochastic_parrot.jpeg){.rounded-shadow}
:::

::: {.column width="20%"}
### vs {style="text-align: center"}
:::

::: {.column width="40%"}
![Machines that Reason](images/machine-reasoning.jpeg){.rounded-shadow}
:::
:::

## Let's (almost) Build a Chatbot {auto-animate="true"}

## Let's (almost) Build a Chatbot {auto-animate="true"}

<!-- ``` {.r code-line-numbers="|3|6|10-11|12-14"} -->

``` r
library(shiny)
library(bslib)
library(shinychat) # pak::pak("jcheng5/shinychat")

ui <- page_fluid(
  chat_ui("chat")
)

server <- function(input, output, session) {
  greeting <- "Hello there. Let's chat!"
  chat_append("chat", greeting)
  observeEvent(input$chat_user_input, {
    chat_append("chat", paste0("You said: ", input$chat_user_input))
  })
}

shinyApp(ui, server)
```

## Let's (almost) Build a Chatbot {auto-animate="true"}

![](images/clipboard-3132120658.png){.rounded-shadow fig-align="center"}

## Meet `elmer` {auto-animate="true"}

![](images/elmer.png){.absolute top="-25" left="800" width="125"}

. . .

<br>

``` r
library(elmer)                # pak::pak("hadley/elmer")
chat <- chat_openai()         # requires api key
```

## Meet `elmer` {auto-animate="true"}

![](images/elmer.png){.absolute top="-25" left="800" width="125"}

<br>

``` r
library(elmer)                # pak::pak("hadley/elmer")
chat <- chat_openai()         # requires api key
chat$chat("Hello there")
#> Hi there! How can I assist you today?
```

## Meet `elmer` {auto-animate="true"}

![](images/elmer.png){.absolute top="-25" left="800" width="125"}

<br>

``` r
library(elmer)                # pak::pak("hadley/elmer")
chat <- chat_openai()         # requires api key
chat$chat("Hello there")
#> Hi there! How can I assist you today?
chat$chat("Tell me a pithy coding joke.")
#> Why do programmers prefer dark mode? Because light attracts bugs!
```

## Meet `elmer` {auto-animate="true"}

![](images/elmer.png){.absolute top="-25" left="800" width="125"}

<br>

``` r
library(elmer)                # pak::pak("hadley/elmer")
chat <- chat_openai()         # requires api key
chat$chat("Hello there")
#> Hi there! How can I assist you today?
chat$chat("Tell me a pithy coding joke.")
#> Why do programmers prefer dark mode? Because light attracts bugs!

# and now with claude
chat <- chat_claude()         # requires api key
```

## Meet `elmer` {auto-animate="true"}

![](images/elmer.png){.absolute top="-25" left="800" width="125"}

<br>

``` r
library(elmer)                # pak::pak("hadley/elmer")
chat <- chat_openai()         # requires api key
chat$chat("Hello there")
#> Hi there! How can I assist you today?
chat$chat("Tell me a pithy coding joke.")
#> Why do programmers prefer dark mode? Because light attracts bugs!

# and now with claude
chat <- chat_claude()         # requires api key
chat$chat("Please solve all my shiny app problems")
#> Of course! I'd be happy to help with any issues with your...
```

## More fun with `elmer` {auto-animate="true"}

![](images/elmer.png){.absolute top="-25" left="800" width="125"}

We can easily pass images.

``` r
library(elmer)
chat <- chat_openai(model = "gpt-4o", echo = TRUE)
img <- "https://github.com/hadley/elmer/raw/main/man/figures/logo.png"
chat$chat("What am I looking at?",
          content_image_url(img))
```

## More fun with `elmer` {auto-animate="true"}

![](images/elmer.png){.absolute top="-25" left="800" width="125"}

We can easily pass images.

``` r
library(elmer)
chat <- chat_openai(model = "gpt-4o", echo = TRUE)
img <- "https://github.com/hadley/elmer/raw/main/man/figures/logo.png"
chat$chat("What am I looking at?",
          content_image_url(img))
#> This is an illustration featuring Elmer the Patchwork
#> Elephant. Elmer is known for his colorful, patchwork
#> appearance, and the image showcases a cheerful,
#> multicolored design typical of the Elmer series of
#> children's books by David McKee.
```

## More fun with `elmer` {auto-animate="true"}

![](images/elmer.png){.absolute top="-25" left="800" width="125"}

We can easily pass images.

``` r
library(elmer)
chat <- chat_openai(model = "gpt-4o", echo = TRUE)
img <- "https://github.com/hadley/elmer/raw/main/man/figures/logo.png"
chat$chat("What am I looking at?",
          content_image_url(img))
#> This is an illustration featuring Elmer the Patchwork
#> Elephant. Elmer is known for his colorful, patchwork
#> appearance, and the image showcases a cheerful,
#> multicolored design typical of the Elmer series of
#> children's books by David McKee.
```

And ask follow up questions...

``` r
chat$chat("In one sentence, does this make sense as a hex sticker for an R
package for LLM APIs?")
#> Yes, it makes sense if the package emphasizes creativity,
#> diversity, or colorful data representation, drawing a
#> parallel with Elmer's vibrant and patchwork theme.
```

## You can pass plots to `elmer` too

```{r}
#| echo: false
#| fig-align: 'center'
#| fig-width: 6
#| fig-height: 4
#| out-extra: .rounded-shadow
library(ggplot2)

set.seed(123)
data <- data.frame(x = rnorm(100), y = rnorm(100) + 0.5 * rnorm(100))

ggplot(data, aes(x = x, y = y)) +
  geom_point(color = "darkorange", fill = "skyblue") +
  geom_smooth(method = "lm", color = "purple", linetype = "dashed") +
  labs(title = "Fun Scatter Plot!", x = "Random X", y = "Random Y") +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(face = "bold", hjust = 0.5))
```

``` r
chat$chat("In a few words, interpret this plot", content_image_plot())
#> No significant trend; random distribution around the mean.
```

## Let's Build (an actual) Chatbot {auto-animate="true" auto-animate-easing="ease-in-out"}

``` {.r code-line-numbers="|8-15"}
library(shiny)

ui <- bslib::page_fluid(
  shinychat::chat_ui("chat")
)

server <- function(input, output, session) {
  chat <- elmer::chat_openai(
    model = "gpt-4o-mini",
    system_prompt = "You are a pithy, but helpful assistant."
  )
  observeEvent(input$chat_user_input, {
    stream <- chat$stream_async(input$chat_user_input)
    shinychat::chat_append("chat", stream)
  })
}

shinyApp(ui, server)
```

## But let's remember Joe's advice... {.center auto-animate="true"}

::: columns
::: {.column width="50%"}
> Being a mere consumer of Copilot and ChatGPT is not enough to have a well-ifcormed opinion of the potential of LLMs (you will miss out on [structured output]{.yellow} and [tool calls]{.yellow}).
>
> **Start coding!**
:::

::: {.column width="50%"}
![](images/robot-assistant.jpeg){.rounded-shadow}
:::
:::

## Tool Calling

An example with the weather:

``` r
# simple chat interface
elmer::live_browser(chat)
```

![](images/clipboard-374887087.png){.rounded-shadow fig-align="center"}

## To use a tool, register it first {.smaller}

::: panel-tabset
### Register Tool

``` r
chat$register_tool(
  tool(
  .fun = get_forecast,
  .description = "Gets 7-day weather forecast for a city",
  # typed arguments
  city = type_string("The name of the city"),
  state = type_string("State name or abbreviation (required)")
  )
)
```

<br>

Types: `type_string()`, `type_integer()`, `type_number()`, `type_boolean()`, `type_array()`, `type_object()`, `type_enum()`

### Tool

``` r
get_forecast <- function(city, state) {
  coords <- get_coordinates(city, state)
  station <- get_nearest_station(coords$lat, coords$lon)

  response <- request(station$forecast_url) |>
    req_headers("Accept" = "application/json", "User-Agent" = "R Weather App (contact@example.com)") |>
    req_perform() |>
    resp_body_json()

  map(response$properties$periods, ~ {
    temp <- as.numeric(gsub("[^0-9.-]", "", .x$temperature))
    list(
      location = coords$location,
      coordinates = list(lat = coords$lat, lon = coords$lon),
      date = .x$startTime,
      name = .x$name,
      temp = temp,
      conditions = .x$shortForecast,
      detailed_forecast = .x$detailedForecast
    )
  })
}
```
:::

## Structured Output

<br>

The model will adhere to a defined schema or structure

. . .

<br>

... which means ...

. . .

<br>

structured output makes LLMs [programmable]{.yellow}!

## Stucture Output - An Example {auto-animate="true"}

```{r}
library(elmer)
library(tibble)
library(gt)
library(dplyr)
bio_joe <- "Joe Cheng is the Chief Technology Officer at Posit, and the original creator of Shiny. He joined RStudio in 2009 to help create the RStudio IDE, and along the way created many web-related R packages, including htmltools, httpuv, promises, and shinymeta. He lives in the suburbs of Seattle, Washington with his wife Amy, three teenage sons, and numerous bicycles."
bio_james <- "James Wade is a Research Scientist working in the chemicals and materials science industry where he combines the power of data science with chemistry and materials science. His current projects focus on augmenting materials characterization innovations with statistical analysis, machine learning, and data visualization. James enjoys contributing to a growing data science community both in and outside of work and is a passionate advocate of open-source data science."
```

```{r}
#| echo: true
chat <- chat_openai(model = "gpt-4o", echo = FALSE, seed = 1234)
bio_spec <- type_object(
  "Person",
  name = type_string("Name of the person"),
  profession = type_string("Profession"),
  interests = type_string("Interests"),
  favorite_pkg = type_string("Favorite R package, say 'Unknown' if none")
)
```

## Stucture Output - An Example {auto-animate="true"}

```{r}
#| echo: true
chat <- chat_openai(model = "gpt-4o", echo = FALSE, seed = 1234)
bio_spec <- type_object(
  "Person",
  name = type_string("Name of the person"),
  profession = type_string("Profession"),
  interests = type_string("Interests"),
  favorite_pkg = type_string("Favorite R package, say 'Unknown' if none")
)
joe <- chat$extract_data(bio_joe, spec = bio_spec)
joe
```

## Stucture Output - An Example {auto-animate="true"}

```{r}
#| echo: true
chat <- chat_openai(model = "gpt-4o", echo = FALSE, seed = 1234)
bio_spec <- type_object(
  "Person",
  name = type_string("Name of the person"),
  profession = type_string("Profession"),
  interests = type_string("Interests"),
  favorite_pkg = type_string("Favorite R package, say 'Unknown' if none")
)

bind_rows(
  chat$extract_data(bio_joe, spec = bio_spec) |> as_tibble(),  # joe's bio
  chat$extract_data(bio_james, spec = bio_spec) |> as_tibble() # my bio
) |> 
  gt() |> 
  opt_stylize(style = 3)
```

## Structured Output

::: columns
::: {.column width="60%"}
<br> LLMs are *fantastic* at converting unstructured text to [structured data]{.yellow}.
:::

::: {.column width="40%"}
![](images/nejm_screenshot.png){.rounded-shadow height="100%"}
:::
:::

## Structured Output {.scrollable}

::: panel-tabset
### Schema

```         
study_info_spec/
├── title (string)
├── authors [array]
│   └── items
│       ├── name (string)
│       └── affiliation (string)
├── published_date (string)
├── journal (string)
├── condition_addressed (string)
├── study_objective (string)
├── study_design (string)
├── participants/
│   ├── number (number)
│   ├── inclusion_criteria (string)
│   └── exclusion_criteria (string)
├── intervention/
│   ├── dosage_groups [array<number>]
│   └── duration (string)
├── outcome_measures/
│   ├── primary_endpoint (string)
│   ├── secondary_endpoints (string)
│   └── exploratory_measures (string)
├── results/
│   ├── primary_outcome (string)
│   ├── secondary_outcomes (string)
│   └── safety_and_adverse_events (string)
└── discussion/
├── efficacy_comparison (string)
├── safety_profile (string)
└── implications (string)
```

### Schema - Code

``` r
study_info_spec <- type_object(
  "Information about a medical research study",
  # Basic study information
  title = type_string("The title of the study."),
  authors = type_array(
    "List of authors with names and affiliations.",
    items = type_object(
      name = type_string("Name of the author."),
      affiliation = type_string("Affiliation of the author.")
    )
  ),
  published_date = type_string("The date the study was published."),
  journal = type_string("The journal in which the study is published."),
  condition_addressed = type_string("The medical condition that is being addressed in the study."),
  study_objective = type_string("The objective of the study."),
  study_design = type_string("The design of the study."),

  # Participant information
  participants = type_object(
    "Details about study participants including criteria.",
    number = type_number("Number of participants in the study."),
    inclusion_criteria = type_string("Inclusion criteria for participants."),
    exclusion_criteria = type_string("Exclusion criteria for participants.")
  ),

  # Intervention details
  intervention = type_object(
    "Details about the interventions conducted in the study.",
    dosage_groups = type_array(
      "Dosage groups for the intervention.",
      items = type_number()
    ),
    duration = type_string("Duration of the study intervention.")
  ),

  # Outcome measures
  outcome_measures = type_object(
    "Details about the outcome measures used in the study.",
    primary_endpoint = type_string("Primary outcome measurement."),
    secondary_endpoints = type_string("Secondary outcome measurements."),
    exploratory_measures = type_string("Exploratory outcome measurements.")
  ),

  # Results
  results = type_object(
    "Results of the study.",
    primary_outcome = type_string("Primary outcome of the study."),
    secondary_outcomes = type_string("Secondary outcomes of the study."),
    safety_and_adverse_events = type_string("Overview of safety and adverse events.")
  ),

  # Discussion
  discussion = type_object(
    "Discussion and conclusions of the study.",
    efficacy_comparison = type_string("Comparison of efficacy with other treatments."),
    safety_profile = type_string("Safety profile comparison."),
    implications = type_string("Implications of the study findings.")
  )
)
```

### Result

```{r}
readr::read_csv("extracted_study_info.csv",
                col_types = readr::cols(.default = "c")) |>
  tidyr::pivot_longer(cols = dplyr::everything()) |>
  gt::gt() |>
  gt::opt_stylize(style = 3)
```

### Code

<br>

``` r
chat <- chat_openai(model = "gpt-4o")             # create chat object
text <- read_pdf(file_path = "NEJMoa2302392.pdf") # extrace text from pdf
extracted_data <- chat$extract_data(              # extra_data call
  text,
  spec = study_info_spec                          # pass custom spec
)
extracted_tbl <- studies_to_table(extracted_data) # convert to table
```
:::

## [Sidebots - Why are they so useful?]{.r-fit-text style="color: rgb(15, 56, 154); background-color: rgba(255, 255, 255, .7);"} {.center background-image="images/r-sidebot.png" style="background-blend-mode: overlay; background-color: rgba(0, 0, 255, 0.3)"}
